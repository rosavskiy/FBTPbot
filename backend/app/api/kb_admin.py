"""
API-—ç–Ω–¥–ø–æ–∏–Ω—Ç—ã –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π Q&A (–∫–≤–∏–∑-—Ä–µ–∂–∏–º + –∏–º–ø–æ—Ä—Ç).

–ü–æ–∑–≤–æ–ª—è–µ—Ç:
- –ü—Ä–æ—Å–º–∞—Ç—Ä–∏–≤–∞—Ç—å Q&A –ø–∞—Ä—ã –∏–∑ JSON-—Ñ–∞–π–ª–∞
- –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã/–æ—Ç–≤–µ—Ç—ã/–º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
- –û–¥–æ–±—Ä—è—Ç—å –ø–∞—Ä—ã (approved)
- –£–¥–∞–ª—è—Ç—å –Ω–µ–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –∑–∞–ø–∏—Å–∏
- –ò–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
- –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Å ChromaDB (–∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ + –ø–æ–ª–Ω—ã–π —Ä–µ–∏–Ω–¥–µ–∫—Å)
"""

from __future__ import annotations

import json
import logging
import shutil
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from fastapi import APIRouter, HTTPException, Query, UploadFile, File
from pydantic import BaseModel, Field

from app.config import settings
from app.indexer.knowledge_base import (
    SUPPORT_COLLECTION_NAME,
    get_indexer,
)

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/kb", tags=["kb-admin"])

# ‚îÄ‚îÄ‚îÄ –ü—É—Ç—å –∫ JSON-—Ñ–∞–π–ª—É –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
# –ù–∞ —Å–µ—Ä–≤–µ—Ä–µ: /app/data/support_kb.json (persistent volume)
# –õ–æ–∫–∞–ª—å–Ω–æ: real_support/processed/support_qa_documents_merged_final.json
_KB_PATHS = [
    Path("/app/data/support_kb.json"),                    # Docker production
    Path("/app/real_support/processed/support_qa_documents_merged_final.json"),  # Docker alt
    Path(__file__).resolve().parents[3] / "real_support" / "processed" / "support_qa_documents_merged_final.json",  # Local dev
]
KB_JSON_PATH = next((p for p in _KB_PATHS if p.exists()), _KB_PATHS[0])

KB_BACKUP_DIR = KB_JSON_PATH.parent / "backups"


# ‚îÄ‚îÄ‚îÄ Pydantic-–º–æ–¥–µ–ª–∏ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

class KBItemMetadata(BaseModel):
    source: str = "real_support_tickets"
    category: str = "–ü—Ä–æ—á–µ–µ"
    category_en: str = "general"
    tags: List[str] = []
    quality_score: int = 3
    question: str = ""
    answer: str = ""
    type: str = "qa_pair"


class KBItem(BaseModel):
    id: str
    text: str
    metadata: KBItemMetadata
    reviewed: bool = False
    review_date: Optional[str] = None


class KBItemUpdate(BaseModel):
    question: Optional[str] = None
    answer: Optional[str] = None
    category: Optional[str] = None
    category_en: Optional[str] = None
    tags: Optional[List[str]] = None
    quality_score: Optional[int] = None


class KBStats(BaseModel):
    total: int = 0
    reviewed: int = 0
    unreviewed: int = 0
    by_category: Dict[str, int] = {}
    by_quality: Dict[str, int] = {}
    avg_quality: float = 0.0


class KBImportResult(BaseModel):
    added: int = 0
    duplicates_skipped: int = 0
    errors: int = 0
    message: str = ""


class KBReindexResult(BaseModel):
    total_documents: int = 0
    duration_seconds: float = 0.0
    message: str = ""


# ‚îÄ‚îÄ‚îÄ –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å JSON-—Ñ–∞–π–ª–æ–º ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

def _load_kb() -> List[Dict[str, Any]]:
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –∏–∑ JSON."""
    if not KB_JSON_PATH.exists():
        raise HTTPException(status_code=404, detail=f"–§–∞–π–ª –ë–ó –Ω–µ –Ω–∞–π–¥–µ–Ω: {KB_JSON_PATH}")
    try:
        with open(KB_JSON_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON: {e}")


def _save_kb(data: List[Dict[str, Any]], backup: bool = True):
    """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –≤ JSON —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –±—ç–∫–∞–ø–æ–º."""
    if backup:
        KB_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_path = KB_BACKUP_DIR / f"kb_backup_{ts}.json"
        if KB_JSON_PATH.exists():
            shutil.copy2(KB_JSON_PATH, backup_path)
            logger.info(f"–ë—ç–∫–∞–ø —Å–æ–∑–¥–∞–Ω: {backup_path}")
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 20 –±—ç–∫–∞–ø–æ–≤
            backups = sorted(KB_BACKUP_DIR.glob("kb_backup_*.json"))
            for old in backups[:-20]:
                old.unlink()

    with open(KB_JSON_PATH, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    logger.info(f"–ë–ó —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {len(data)} –∑–∞–ø–∏—Å–µ–π -> {KB_JSON_PATH}")


def _update_chromadb_document(item: Dict[str, Any]):
    """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å –æ–¥–∏–Ω –¥–æ–∫—É–º–µ–Ω—Ç –≤ ChromaDB."""
    try:
        indexer = get_indexer()
        store = indexer.get_support_vector_store()
        if store is None:
            logger.warning("support_vector_store –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ChromaDB")
            return

        collection = store._collection
        doc_id = item["id"]
        metadata = item.get("metadata", {})

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö (ChromaDB –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Å–ø–∏—Å–∫–∏)
        clean_meta = {
            "source": metadata.get("source", "real_support_tickets"),
            "category": metadata.get("category", "–ü—Ä–æ—á–µ–µ"),
            "category_en": metadata.get("category_en", "general"),
            "quality_score": metadata.get("quality_score", 0),
            "question": metadata.get("question", "")[:500],
            "doc_type": metadata.get("type", "qa_pair"),
            "article_id": f"tp_{doc_id}",
            "title": metadata.get("question", "–ó–∞—è–≤–∫–∞ –¢–ü")[:200],
        }
        if metadata.get("tags"):
            clean_meta["tags"] = ", ".join(metadata["tags"])
        if item.get("reviewed"):
            clean_meta["reviewed"] = "true"

        text = item["text"]

        # –ü—Ä–æ–±—É–µ–º –æ–±–Ω–æ–≤–∏—Ç—å, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º
        existing = collection.get(ids=[doc_id])
        if existing and existing["ids"]:
            collection.update(
                ids=[doc_id],
                documents=[text],
                metadatas=[clean_meta],
            )
            logger.info(f"ChromaDB: –æ–±–Ω–æ–≤–ª—ë–Ω –¥–æ–∫—É–º–µ–Ω—Ç {doc_id}")
        else:
            collection.add(
                ids=[doc_id],
                documents=[text],
                metadatas=[clean_meta],
            )
            logger.info(f"ChromaDB: –¥–æ–±–∞–≤–ª–µ–Ω –¥–æ–∫—É–º–µ–Ω—Ç {doc_id}")

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è ChromaDB –¥–ª—è {item.get('id')}: {e}")


def _delete_chromadb_document(doc_id: str):
    """–£–¥–∞–ª–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç –∏–∑ ChromaDB."""
    try:
        indexer = get_indexer()
        store = indexer.get_support_vector_store()
        if store is None:
            return
        collection = store._collection
        collection.delete(ids=[doc_id])
        logger.info(f"ChromaDB: —É–¥–∞–ª—ë–Ω –¥–æ–∫—É–º–µ–Ω—Ç {doc_id}")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è –∏–∑ ChromaDB {doc_id}: {e}")


# ‚îÄ‚îÄ‚îÄ –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

@router.get("/stats", response_model=KBStats)
async def get_kb_stats():
    """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π."""
    data = _load_kb()
    by_category: Dict[str, int] = {}
    by_quality: Dict[str, int] = {}
    reviewed = 0
    total_quality = 0.0

    for item in data:
        meta = item.get("metadata", {})
        cat = meta.get("category", "–ü—Ä–æ—á–µ–µ")
        by_category[cat] = by_category.get(cat, 0) + 1

        qs = str(meta.get("quality_score", 0))
        by_quality[qs] = by_quality.get(qs, 0) + 1
        total_quality += meta.get("quality_score", 0)

        if item.get("reviewed"):
            reviewed += 1

    return KBStats(
        total=len(data),
        reviewed=reviewed,
        unreviewed=len(data) - reviewed,
        by_category=by_category,
        by_quality=by_quality,
        avg_quality=round(total_quality / max(len(data), 1), 2),
    )


@router.get("/items")
async def list_kb_items(
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100),
    category: Optional[str] = None,
    reviewed: Optional[bool] = None,
    quality_min: Optional[int] = None,
    quality_max: Optional[int] = None,
    search: Optional[str] = None,
):
    """–°–ø–∏—Å–æ–∫ Q&A –ø–∞—Ä —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π."""
    data = _load_kb()

    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è
    if category:
        data = [d for d in data if d.get("metadata", {}).get("category") == category]
    if reviewed is not None:
        data = [d for d in data if d.get("reviewed", False) == reviewed]
    if quality_min is not None:
        data = [d for d in data if d.get("metadata", {}).get("quality_score", 0) >= quality_min]
    if quality_max is not None:
        data = [d for d in data if d.get("metadata", {}).get("quality_score", 0) <= quality_max]
    if search:
        search_lower = search.lower()
        data = [
            d for d in data
            if search_lower in d.get("metadata", {}).get("question", "").lower()
            or search_lower in d.get("metadata", {}).get("answer", "").lower()
            or search_lower in d.get("text", "").lower()
        ]

    total = len(data)
    start = (page - 1) * page_size
    end = start + page_size

    return {
        "items": data[start:end],
        "total": total,
        "page": page,
        "page_size": page_size,
        "total_pages": (total + page_size - 1) // page_size,
    }


@router.get("/items/{item_id}")
async def get_kb_item(item_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –æ–¥–Ω—É Q&A –ø–∞—Ä—É."""
    data = _load_kb()
    for item in data:
        if item.get("id") == item_id:
            return item
    raise HTTPException(status_code=404, detail=f"–≠–ª–µ–º–µ–Ω—Ç {item_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")


@router.get("/quiz/next")
async def get_next_quiz_item(
    category: Optional[str] = None,
    skip_reviewed: bool = True,
):
    """
    –ü–æ–ª—É—á–∏—Ç—å —Å–ª–µ–¥—É—é—â—É—é –Ω–µ–æ—Ç—Ä–µ–≤—å—é–µ–Ω–Ω—É—é Q&A –ø–∞—Ä—É –¥–ª—è –∫–≤–∏–∑–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —ç–ª–µ–º–µ–Ω—Ç + –æ–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å.
    """
    data = _load_kb()

    candidates = data
    if category:
        candidates = [d for d in candidates if d.get("metadata", {}).get("category") == category]
    if skip_reviewed:
        candidates = [d for d in candidates if not d.get("reviewed", False)]

    total = len(data)
    reviewed_count = sum(1 for d in data if d.get("reviewed", False))

    if not candidates:
        return {
            "item": None,
            "progress": {
                "total": total,
                "reviewed": reviewed_count,
                "remaining": 0,
                "percent": 100.0 if total > 0 else 0.0,
            },
            "message": "–í—Å–µ –∑–∞–ø–∏—Å–∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã! üéâ",
        }

    item = candidates[0]
    idx = data.index(item)

    return {
        "item": item,
        "index": idx,
        "progress": {
            "total": total,
            "reviewed": reviewed_count,
            "remaining": len(candidates),
            "percent": round(reviewed_count / max(total, 1) * 100, 1),
        },
    }


@router.put("/items/{item_id}")
async def update_kb_item(item_id: str, update: KBItemUpdate):
    """–û–±–Ω–æ–≤–∏—Ç—å Q&A –ø–∞—Ä—É (–≤–æ–ø—Ä–æ—Å, –æ—Ç–≤–µ—Ç, –∫–∞—Ç–µ–≥–æ—Ä–∏—é, —Ç–µ–≥–∏ –∏ —Ç.–¥.)."""
    data = _load_kb()

    found_idx = None
    for idx, item in enumerate(data):
        if item.get("id") == item_id:
            found_idx = idx
            break

    if found_idx is None:
        raise HTTPException(status_code=404, detail=f"–≠–ª–µ–º–µ–Ω—Ç {item_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    item = data[found_idx]
    meta = item.get("metadata", {})

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    if update.question is not None:
        meta["question"] = update.question
    if update.answer is not None:
        meta["answer"] = update.answer
    if update.category is not None:
        meta["category"] = update.category
    if update.category_en is not None:
        meta["category_en"] = update.category_en
    if update.tags is not None:
        meta["tags"] = update.tags
    if update.quality_score is not None:
        meta["quality_score"] = update.quality_score

    # –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
    q = meta.get("question", "")
    a = meta.get("answer", "")
    item["text"] = f"–í–æ–ø—Ä–æ—Å: {q}\n\n–û—Ç–≤–µ—Ç: {a}"
    item["metadata"] = meta

    data[found_idx] = item
    _save_kb(data)

    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º ChromaDB
    _update_chromadb_document(item)

    return {"status": "ok", "item": item}


@router.post("/items/{item_id}/approve")
async def approve_kb_item(item_id: str):
    """–û–¥–æ–±—Ä–∏—Ç—å Q&A –ø–∞—Ä—É (–ø–æ–º–µ—Ç–∏—Ç—å –∫–∞–∫ –ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—É—é, quality_score=5)."""
    data = _load_kb()

    found_idx = None
    for idx, item in enumerate(data):
        if item.get("id") == item_id:
            found_idx = idx
            break

    if found_idx is None:
        raise HTTPException(status_code=404, detail=f"–≠–ª–µ–º–µ–Ω—Ç {item_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    item = data[found_idx]
    item["reviewed"] = True
    item["review_date"] = datetime.now().isoformat()
    meta = item.get("metadata", {})
    meta["quality_score"] = 5
    item["metadata"] = meta

    data[found_idx] = item
    _save_kb(data)

    # –ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ –æ–±–Ω–æ–≤–ª—è–µ–º ChromaDB
    _update_chromadb_document(item)

    return {"status": "ok", "item": item}


@router.post("/items/{item_id}/save-and-approve")
async def save_and_approve_kb_item(item_id: str, update: KBItemUpdate):
    """–û–±–Ω–æ–≤–∏—Ç—å –∏ —Å—Ä–∞–∑—É –æ–¥–æ–±—Ä–∏—Ç—å Q&A –ø–∞—Ä—É."""
    data = _load_kb()

    found_idx = None
    for idx, item in enumerate(data):
        if item.get("id") == item_id:
            found_idx = idx
            break

    if found_idx is None:
        raise HTTPException(status_code=404, detail=f"–≠–ª–µ–º–µ–Ω—Ç {item_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    item = data[found_idx]
    meta = item.get("metadata", {})

    # –ü—Ä–∏–º–µ–Ω—è–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è
    if update.question is not None:
        meta["question"] = update.question
    if update.answer is not None:
        meta["answer"] = update.answer
    if update.category is not None:
        meta["category"] = update.category
    if update.category_en is not None:
        meta["category_en"] = update.category_en
    if update.tags is not None:
        meta["tags"] = update.tags
    if update.quality_score is not None:
        meta["quality_score"] = update.quality_score
    else:
        meta["quality_score"] = 5

    # –ü–µ—Ä–µ—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç
    q = meta.get("question", "")
    a = meta.get("answer", "")
    item["text"] = f"–í–æ–ø—Ä–æ—Å: {q}\n\n–û—Ç–≤–µ—Ç: {a}"
    item["metadata"] = meta
    item["reviewed"] = True
    item["review_date"] = datetime.now().isoformat()

    data[found_idx] = item
    _save_kb(data)

    _update_chromadb_document(item)

    return {"status": "ok", "item": item}


@router.delete("/items/{item_id}")
async def delete_kb_item(item_id: str):
    """–£–¥–∞–ª–∏—Ç—å Q&A –ø–∞—Ä—É –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π."""
    data = _load_kb()

    found_idx = None
    for idx, item in enumerate(data):
        if item.get("id") == item_id:
            found_idx = idx
            break

    if found_idx is None:
        raise HTTPException(status_code=404, detail=f"–≠–ª–µ–º–µ–Ω—Ç {item_id} –Ω–µ –Ω–∞–π–¥–µ–Ω")

    removed = data.pop(found_idx)
    _save_kb(data)

    _delete_chromadb_document(item_id)

    return {"status": "ok", "deleted_id": item_id, "remaining": len(data)}


@router.post("/import", response_model=KBImportResult)
async def import_kb_data(file: UploadFile = File(...)):
    """
    –ò–º–ø–æ—Ä—Ç –Ω–æ–≤—ã—Ö Q&A –¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON-—Ñ–∞–π–ª–∞.
    –î—É–±–ª–∏–∫–∞—Ç—ã (–ø–æ id) –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è, –Ω–æ–≤—ã–µ –∑–∞–ø–∏—Å–∏ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è.
    """
    try:
        content = await file.read()
        new_items = json.loads(content.decode("utf-8"))
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞: {e}")

    if not isinstance(new_items, list):
        raise HTTPException(status_code=400, detail="–û–∂–∏–¥–∞–µ—Ç—Å—è JSON-–º–∞—Å—Å–∏–≤")

    data = _load_kb()
    existing_ids = {item["id"] for item in data}

    added = 0
    duplicates = 0
    errors = 0

    for new_item in new_items:
        try:
            if not isinstance(new_item, dict) or "id" not in new_item:
                errors += 1
                continue

            if new_item["id"] in existing_ids:
                duplicates += 1
                continue

            # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –µ—Å—Ç—å –≤—Å–µ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
            if "text" not in new_item:
                meta = new_item.get("metadata", {})
                q = meta.get("question", "")
                a = meta.get("answer", "")
                new_item["text"] = f"–í–æ–ø—Ä–æ—Å: {q}\n\n–û—Ç–≤–µ—Ç: {a}"

            if "metadata" not in new_item:
                new_item["metadata"] = {
                    "source": "real_support_tickets",
                    "category": "–ü—Ä–æ—á–µ–µ",
                    "category_en": "general",
                    "tags": [],
                    "quality_score": 3,
                    "question": "",
                    "answer": "",
                    "type": "qa_pair",
                }

            new_item["reviewed"] = False
            data.append(new_item)
            existing_ids.add(new_item["id"])
            added += 1

            # –î–æ–±–∞–≤–ª—è–µ–º –≤ ChromaDB
            _update_chromadb_document(new_item)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            errors += 1

    _save_kb(data)

    return KBImportResult(
        added=added,
        duplicates_skipped=duplicates,
        errors=errors,
        message=f"–ò–º–ø–æ—Ä—Ç –∑–∞–≤–µ—Ä—à—ë–Ω: +{added} –Ω–æ–≤—ã—Ö, {duplicates} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –ø—Ä–æ–ø—É—â–µ–Ω–æ, {errors} –æ—à–∏–±–æ–∫",
    )


@router.post("/reindex", response_model=KBReindexResult)
async def reindex_kb():
    """
    –ü–æ–ª–Ω–∞—è –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è support_tickets –≤ ChromaDB –∏–∑ JSON-—Ñ–∞–π–ª–∞.
    –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ø–æ—Å–ª–µ –º–∞—Å—Å–æ–≤—ã—Ö –ø—Ä–∞–≤–æ–∫.
    """
    import time

    start = time.time()

    try:
        indexer = get_indexer()
        count = indexer.index_support_tickets(KB_JSON_PATH)

        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∫–µ—à vector_store –≤ RAG-–¥–≤–∏–∂–∫–µ
        from app.rag.engine import _engine as _rag_engine
        if _rag_engine is not None and hasattr(_rag_engine, '_support_vector_store'):
            delattr(_rag_engine, '_support_vector_store')
            logger.info("–ö–µ—à support_vector_store –≤ RAG-–¥–≤–∏–∂–∫–µ —Å–±—Ä–æ—à–µ–Ω")

        # –¢–∞–∫–∂–µ —Å–±—Ä–æ—Å–∏–º –∫–µ—à –≤ –∏–Ω–¥–µ–∫—Å–∞—Ç–æ—Ä–µ
        indexer.support_vector_store = None

        duration = round(time.time() - start, 2)
        return KBReindexResult(
            total_documents=count,
            duration_seconds=duration,
            message=f"–ü–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∑–∞ {duration}—Å",
        )
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")


@router.get("/categories")
async def get_categories():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π."""
    data = _load_kb()
    categories = {}
    for item in data:
        cat = item.get("metadata", {}).get("category", "–ü—Ä–æ—á–µ–µ")
        cat_en = item.get("metadata", {}).get("category_en", "general")
        categories[cat] = cat_en
    return {"categories": categories}
